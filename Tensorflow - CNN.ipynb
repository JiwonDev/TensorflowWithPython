{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 설명\n",
    " - Filter = 말 그대로 필터, 데이터의 '특정 부분'만 추출해서 보는방법.\n",
    " - Stride = 필터가 움직이는 크기\n",
    " - Output 크기 = { ( N - F ) / Stride }  +   1(처음값)\n",
    " ![ㅎㅇ](https://img1.daumcdn.net/thumb/R720x0.q80/?scode=mtistory&fname=http%3A%2F%2Fcfile8.uf.tistory.com%2Fimage%2F261CE14F57AB46151178C3)\n",
    " \n",
    " <br><br><br>\n",
    " \n",
    " - padding(끝부분을 0으로 채움)을 이용해서 입력과 출력이 같아지게 만들수도 있어요.\n",
    " - 당연히 0은 학습이 되지않기 때문에, 이는 필요없는 부분을 짤라주는 효과도 있습니다.\n",
    " ![ㅎㅇ](https://img1.daumcdn.net/thumb/R720x0.q80/?scode=mtistory&fname=http%3A%2F%2Fcfile7.uf.tistory.com%2Fimage%2F2610394F57AB461620C491)\n",
    "  <br><br><br>\n",
    " \n",
    " - 이런식으로 필터를 원하는 만큼 뽑아냅니다.\n",
    " 행렬은 [ (Output) , 깊이 ] 가 될테니 이 그림에서 Stride가 7일 때, [28,28,필터갯수] 이 나오게 됩니다.\n",
    " ![ㅎㅇ](https://img1.daumcdn.net/thumb/R720x0.q80/?scode=mtistory&fname=http%3A%2F%2Fcfile8.uf.tistory.com%2Fimage%2F212C3A4F57AB461802BBC3)\n",
    "   <br><br><br>\n",
    " - 이런 과정을 여러번 반복하고 RELU로 값을 맞추고, 또 필터로 추출해서 반복..... 하여 결국 원하는 값을 추측(예상)하게 됩니다.\n",
    " Tensorflow는 한 필터의 깊이, 즉 필터의 갯수를 Channel이라 부릅니다.\n",
    " ![ㅎㅇ](https://img1.daumcdn.net/thumb/R720x0.q80/?scode=mtistory&fname=http%3A%2F%2Fcfile4.uf.tistory.com%2Fimage%2F2515E24F57AB4619194CF9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<br><br><br>\n",
    "## 실제 그림인식할 때의 예시를 보자.\n",
    "http://cs.stanford.edu/people/karpathy/convnetjs/demo/cifar10.html 이 링크를 이용하면 좀 더 쉽게 이해가능하다.\n",
    "1. 우선 데이터(실제사진)을 구한다. 이미지 크기 X 채널 갯수 (필터로 뽑아내기 나름)\n",
    "2. 이를 Conv 크기에 맞추기 + 쓸모없는 가장자리 부분을 잘라내기를 위하여 끝부분을 0으로 Padding한다.\n",
    "3. stride(보폭)을 적절하게 설정하고, 원하는 갯수만큼 필터링하여 우리의 학습모델과 이미지크기X채널 수를 맞춘다.\n",
    "4. 기존의 학습데이터(혹은 W초기값)를 이용하여 예측한 결과를 뽑아낸다\n",
    "5. 뽑아낸 결과를 ReLU를 이용하여 정리한다.\n",
    "6. 결과물의 크기를 바꾼다 (Pooling)\n",
    "7. Conv, Pooling, ReLU를 적절히 섞어서 레이어를 구성한다. 섞는거 방식에 따라 학습 결과는 달라진다.\n",
    "8. 학습한 최종 결과물을 Sofemax등의 함수를 이용하여 실제값으로 변경한다. (Fully Connected)\n",
    "9. 실제값[0,0,0,0,1,0] 을 읽어서 이 그림이 뭔지 맞춘다!\n",
    "<br>\n",
    "\n",
    "![ㅎㅇ](https://img1.daumcdn.net/thumb/R720x0.q80/?scode=mtistory&fname=http%3A%2F%2Fcfile3.uf.tistory.com%2Fimage%2F240C453757AB54E8105A1E)\n",
    "이런식으로 레이어를 구성하게되고, 위에서 설명한 Convolution -> ReLU -> Pooling을 진행하여 값을 얻는다.\n",
    "물론 이 레이어 순서는 바꿔도 상관없다. 학습 결과가 달라질 뿐. (코딩하기 나름)\n",
    "<br><br><br>\n",
    "## Pooling (모으다) ?\n",
    "간단하게 Sampling(샘플추출) 혹은 Resizeing(크기변경) 이라고 생각하면 된다. \n",
    "크기를 변경할 때 어떤값을 고를 것인가?, 이 예제는 MAX POOLING을 사용해서 가장 큰 값을 선택하여 크기를 바꾼다.\n",
    "![ㅎㅇ](https://img1.daumcdn.net/thumb/R720x0.q80/?scode=mtistory&fname=http%3A%2F%2Fcfile5.uf.tistory.com%2Fimage%2F2519E53757AB54E907C5F8)\n",
    "<br><br><br>\n",
    "\n",
    "## FC(Fully Connected) ?\n",
    "우리가 CNN 이전에 배웠던것을 Fully Connected라 부른다.\n",
    "말 그대로 처음부터 끝까지 하나로 연결 되있는, 마지막에 결과를 추출하는 부분을 말한다. (Softmax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

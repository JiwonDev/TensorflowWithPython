{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 설명\n",
    " - Filter = 말 그대로 필터, 데이터의 '특정 부분'만 추출해서 보는방법.\n",
    " - Stride = 필터가 움직이는 크기\n",
    " - Output 크기 = { ( N - F ) / Stride }  +   1(처음값)\n",
    " ![ㅎㅇ](https://img1.daumcdn.net/thumb/R720x0.q80/?scode=mtistory&fname=http%3A%2F%2Fcfile8.uf.tistory.com%2Fimage%2F261CE14F57AB46151178C3)\n",
    " \n",
    " <br><br><br>\n",
    " \n",
    " - padding(끝부분을 0으로 채움)을 이용해서 입력과 출력이 같아지게 만들수도 있어요.\n",
    " - 당연히 0은 학습이 되지않기 때문에, 이는 필요없는 부분을 짤라주는 효과도 있습니다.\n",
    " ![ㅎㅇ](https://img1.daumcdn.net/thumb/R720x0.q80/?scode=mtistory&fname=http%3A%2F%2Fcfile7.uf.tistory.com%2Fimage%2F2610394F57AB461620C491)\n",
    "  <br><br><br>\n",
    " \n",
    " - 이런식으로 필터를 원하는 만큼 뽑아냅니다.\n",
    " 행렬은 [ (Output) , 깊이 ] 가 될테니 이 그림에서 Stride가 7일 때, [28,28,필터갯수] 이 나오게 됩니다.\n",
    " ![ㅎㅇ](https://img1.daumcdn.net/thumb/R720x0.q80/?scode=mtistory&fname=http%3A%2F%2Fcfile8.uf.tistory.com%2Fimage%2F212C3A4F57AB461802BBC3)\n",
    "   <br><br><br>\n",
    " - 이런 과정을 여러번 반복하고 RELU로 값을 맞추고, 또 필터로 추출해서 반복..... 하여 결국 원하는 값을 추측(예상)하게 됩니다.\n",
    " Tensorflow는 한 필터의 깊이, 즉 필터의 갯수를 Channel이라 부릅니다.\n",
    " ![ㅎㅇ](https://img1.daumcdn.net/thumb/R720x0.q80/?scode=mtistory&fname=http%3A%2F%2Fcfile4.uf.tistory.com%2Fimage%2F2515E24F57AB4619194CF9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<br><br><br>\n",
    "## 실제 그림인식할 때의 예시를 보자.\n",
    "http://cs.stanford.edu/people/karpathy/convnetjs/demo/cifar10.html 이 링크를 이용하면 좀 더 쉽게 이해가능하다.\n",
    "1. 우선 데이터(실제사진)을 구한다. 이미지 크기 X 채널 갯수 (필터로 뽑아내기 나름)\n",
    "2. 이를 Conv 크기에 맞추기 + 쓸모없는 가장자리 부분을 잘라내기를 위하여 끝부분을 0으로 Padding한다.\n",
    "3. stride(보폭)을 적절하게 설정하고, 원하는 갯수만큼 필터링하여 우리의 학습모델과 이미지크기X채널 수를 맞춘다.\n",
    "4. 기존의 학습데이터(혹은 W초기값)를 이용하여 예측한 결과를 뽑아낸다\n",
    "5. 뽑아낸 결과를 ReLU를 이용하여 정리한다.\n",
    "6. 결과물의 크기를 바꾼다 (Pooling)\n",
    "7. Conv, Pooling, ReLU를 적절히 섞어서 레이어를 구성한다. 섞는거 방식에 따라 학습 결과는 달라진다.\n",
    "8. 학습한 최종 결과물을 Sofemax등의 함수를 이용하여 실제값으로 변경한다. (Fully Connected)\n",
    "9. 실제값[0,0,0,0,1,0] 을 읽어서 이 그림이 뭔지 맞춘다!\n",
    "<br>\n",
    "\n",
    "![ㅎㅇ](https://img1.daumcdn.net/thumb/R720x0.q80/?scode=mtistory&fname=http%3A%2F%2Fcfile3.uf.tistory.com%2Fimage%2F240C453757AB54E8105A1E)\n",
    "이런식으로 레이어를 구성하게되고, 위에서 설명한 Convolution -> ReLU -> Pooling을 진행하여 값을 얻는다.\n",
    "물론 이 레이어 순서는 바꿔도 상관없다. 학습 결과가 달라질 뿐. (코딩하기 나름)\n",
    "<br><br><br>\n",
    "## Pooling (모으다) ?\n",
    "간단하게 Sampling(샘플추출) 혹은 Resizeing(크기변경) 이라고 생각하면 된다. \n",
    "크기를 변경할 때 어떤값을 고를 것인가?, 이 예제는 MAX POOLING을 사용해서 가장 큰 값을 선택하여 크기를 바꾼다.\n",
    "![ㅎㅇ](https://img1.daumcdn.net/thumb/R720x0.q80/?scode=mtistory&fname=http%3A%2F%2Fcfile5.uf.tistory.com%2Fimage%2F2519E53757AB54E907C5F8)\n",
    "<br><br><br>\n",
    "\n",
    "## FC(Fully Connected) ?\n",
    "우리가 CNN 이전에 배웠던것을 Fully Connected라 부른다.\n",
    "X의 입력에 따라 Y를 출력하는 것. (분류하는 것)\n",
    "말 그대로 처음부터 끝까지 하나로 연결 되있는, 마지막에 결과를 추출하는 부분을 말한다. ( 이 값을 Softmax!)\n",
    "\n",
    "+ https://www.slideshare.net/leeseungeun/cnn-vgg-72164295\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "# LeNet-5\n",
    "- LeCun et. al. 1998 , Convolution net의 시초라고 할 수 있는 고전모델.\n",
    "![ㅎㅇ](https://img1.daumcdn.net/thumb/R720x0.q80/?scode=mtistory&fname=http%3A%2F%2Fcfile2.uf.tistory.com%2Fimage%2F2777003557AB5C0634C4E7)\n",
    "\n",
    "글자 인식을 위하여 총 6개의 hidden Layer를 사용하고있다. 생각보다 단순한 형태\n",
    "1. Input - 크기 32x32x1. 흑백 이미지. (필터 5x5, stride 1)\n",
    "2. C1 - 크기 28x28x6. feature maps 6개. (필터 5x5, stride 1)\n",
    "3. S2 - 크기 14x14x6. feature maps 6개. (필터 2x2, subsampling)\n",
    "4. C3 - 크기 10x10x16. feature maps 16개\n",
    "5. S4 - 크기 5x5x16. feature maps 16개.\n",
    "6. C5 - FC(Full Connection )120개\n",
    "7. F6 - FC(Full Connection) 84개\n",
    "8. Output - GC(Gaussian Connections) 10개. (최종 분류)\n",
    "\n",
    "<br><br><br>\n",
    "\n",
    "# AlexNet\n",
    " - Krizhevsky et al. 2012, 이미지넷에 나와 NN의 암흑기를 깨준 모델\n",
    " ![ㅎㅇ](https://img1.daumcdn.net/thumb/R720x0.q80/?scode=mtistory&fname=http%3A%2F%2Fcfile7.uf.tistory.com%2Fimage%2F2326693557AB5C07168B0E)\n",
    " 1 Input - 크기 227x227x3 이미지, 필터는 R,G,B 따로라서 총 3개.\n",
    " <br><br>\n",
    " 2 첫번째 Conv의 96개의 필터를 사용하며 크기는 11x11, stride는 4이다.\n",
    " - 필터에 따른 출력의 수는, 위에도 나와있지만  { ( N - F ) / Stride } + 1(처음값)\n",
    " - 즉 { (227 - 11) / 4 }+ 1 = 55개, 전체크기는 55x55x96 이다.  , 입력하는 파라미터 수는 [11*11*3*96] 대략 35K이다.\n",
    " - W는11*11*3 , 파라미터(한픽셀)은 35K라서 한번 학습하는데 며칠씩 걸리는게 당연하다.\n",
    " <br><br>\n",
    " 3 그 외 HiddenLayer가 상당히 깊다. 하지만 하나씩 보면 그렇게 어려운건 아니니 아래 그림 참조\n",
    "- 참고로 NORM (Normalization)은 일반화를 해주는 층인데, 요즘은 그다지 효과가 없는걸로 밝혀져서 잘 안쓴다..\n",
    "- PT에도 적혀있지만 7개의 CNN을 합쳐서(앙상블, ensemble) 에러를 18%->15% 로 줄였다.\n",
    " <br>\n",
    " ![ㅎㅇ](https://img1.daumcdn.net/thumb/R720x0.q80/?scode=mtistory&fname=http%3A%2F%2Fcfile23.uf.tistory.com%2Fimage%2F213E6B3557AB5C0807A3C4)\n",
    " <br><br><br>\n",
    " # GoogLeNet\n",
    " - Szegedy et al. 2014, Google Inception(인셉션, 영화이름 맞아요) Model, ..이미지넷에서 94% 찍어버렸다. \n",
    " - 참고로 Google에서 출전했고 LeNet을 기념하는 의미로 GoogLeNet이라고 이름을 지었다고 한다.\n",
    " 2012년 AlexNet을 시작으로 다양한 시도/연구가 진행되어 탄생한 특이한 모양(?)의 CNN.<br>\n",
    " 레고마냥 같은 레이어에 여러크기의 Conv 필터를 적용하여 구성하였고, 상당히 깊은(Deep) 네트워크이다.\n",
    " ![ㅎㅇ](https://img1.daumcdn.net/thumb/R720x0.q80/?scode=mtistory&fname=http%3A%2F%2Fcfile27.uf.tistory.com%2Fimage%2F2218903557AB5C091F8AD4)\n",
    " <br><br><br>\n",
    " # ResNet\n",
    " - He et al. 2015 , Revolution of Depth 따끈따끈한 모델로 오답률을 3.6%(5개 에러)로 사람을 이겨버렸다!\n",
    " 해를 거듭할수록 Layer의 수는 미친듯이 늘어나고 있다. 이 모델은 152계층의 layer를 사용했다고 ㄷㄷ;\n",
    " ![ㅎㅇ](https://img1.daumcdn.net/thumb/R720x0.q80/?scode=mtistory&fname=http%3A%2F%2Fcfile30.uf.tistory.com%2Fimage%2F257BED3A57AB5C0A07823A)\n",
    " <br><br>\n",
    " 이런 Deep Layer를 어떻게 학습했냐면, 몇 계층마다 랜덤으로 점프(?)를 해서 깊지않은것과 비슷하게 학습 했다고 한다.\n",
    " (하지만 이렇게 해도 학습하는데 2~3주동안 8개의 GPU를 계속해서 돌려야 했다고...)<br>\n",
    " 그래서 여러개의 Layer를 건너뛰어서 빨리 도착한다고 Fast net이라고 부르기도 한다고.<br>\n",
    " 물론 대부분의 NN이 그렇듯, 왜 그런지 정확하게 증명은 하지 못한다. \n",
    " ![ㅎㅇ](https://img1.daumcdn.net/thumb/R720x0.q80/?scode=mtistory&fname=http%3A%2F%2Fcfile27.uf.tistory.com%2Fimage%2F2771DF3A57AB5C0B0AA110)\n",
    " ![ㅎㅇ](https://img1.daumcdn.net/thumb/R720x0.q80/?scode=mtistory&fname=http%3A%2F%2Fcfile25.uf.tistory.com%2Fimage%2F2117B43A57AB5C0B284C3F)\n",
    " \n",
    " <br><br><br> \n",
    " # CNN for Sentence Classification (문장분석 CNN)\n",
    " - Yoon Kim 2014, 한국인 윤김 교수님께서 만드셨고 현재도 많이 사용하는 모델이다\n",
    " ![ㅎㅇ](https://img1.daumcdn.net/thumb/R720x0.q80/?scode=mtistory&fname=http%3A%2F%2Fcfile10.uf.tistory.com%2Fimage%2F247CEB3A57AB5C0C39532C)\n",
    " <br><br><br>\n",
    " # DeepMind's AlphaGo\n",
    " - 설명이 필요한가?\n",
    " ![ㅎㅇ](https://img1.daumcdn.net/thumb/R720x0.q80/?scode=mtistory&fname=http%3A%2F%2Fcfile10.uf.tistory.com%2Fimage%2F2119AC3A57AB5C0D2B7F14)\n",
    " 국제적인 학술지(네이쳐) 논문에 대략적인 설명이 적혀있다.\n",
    " ![ㅎㅇ](https://img1.daumcdn.net/thumb/R720x0.q80/?scode=mtistory&fname=http%3A%2F%2Fcfile7.uf.tistory.com%2Fimage%2F240D473A57AB5C0E02D4BB)\n",
    " 19x19x48 이미지 스택을 사용하고 있다. 바둑은 19x19개의 칸으로 구성되어 있다. 즉, 바둑판 이미지를 읽을 지는 모르지만, 19픽셀로 재구성하고 있음을 알 수 있다. 이후 이미지 크기를 패딩을 적용해서 23x23으로 바꾸었다고 설명하고 있다. 48개의 feature planes(채널)를 사용했다는 것은 바둑돌이 하나 놓여질 때마다 해당 돌의 특징을 48가지로 판단했음을 뜻한다. 가령, 흑돌인지 백돌인지, 주변에 흑돌이 있는지 백돌이 있는지, 현재 정세가 어떠한지 등등.\n",
    " \n",
    " <br><br><br>\n",
    " # 이런걸 왜 보여주나?\n",
    " 아직 \"따끈따끈한' 주제라는 말이다!\n",
    " 해를 거듭할수록 참신한 아이디어가 계속 나오고 있고\n",
    " 이번년도에는 또 어떤게 나올지 기대된다. (최신 논문을 자주 봐야하는 이유?)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "------------------------------\n",
    "# 직접 구현배보자.\n",
    "우선, 앞에 있던 구조를 보면 알겠지만 CNN의 구조는 크게 3등분 할 수 있다.\n",
    "1. 입력된 이미지를 Convolution으로 원하는 만큼 뽑아낸다. (필터링)\n",
    "2. 이를 Subsampling 해서 작게 쪼개고, 원하는 만큼 Conv 반복하여 특징을 뽑아낸다 (feature Extraction)\n",
    "3. 이를 통해 나온 결과를 FC한다. (classification)\n",
    "![ㅎㅇ](https://img1.daumcdn.net/thumb/R720x0.q80/?scode=mtistory&fname=http%3A%2F%2Fcfile5.uf.tistory.com%2Fimage%2F25321C4857ABEB59202196)\n",
    "\n",
    "## Tensorflow는 Conv 쉽게 해라고 메서드를 제공해줍니다.\n",
    "    tf.nn.conv2d(input, filter, strides, padding, use_cudnn_on_gpu=None, data_format=None, name=None)\n",
    "\n",
    "  input : [batch, in_height, in_width, in_channels] 형식. 28x28x1 형식의 손글씨 이미지. <br>\n",
    "  filter : [filter_height, filter_width, in_channels, out_channels] 형식. 3, 3, 1, 32의 w.<br>\n",
    "  strides : 크기 4인 1차원 리스트. [0], [3]은 반드시 1. 일반적으로 [1], [2]는 같은 값 사용.<br>\n",
    "  padding : 'SAME' 또는 'VALID'. 패딩을 추가하는 공식의 차이. SAME은 출력 크기를 입력과 같게 유지.<br>\n",
    "<br><br>\n",
    "3x3x1 필터를 32개 만드는 것을 코드로 표현하면 [3, 3, 1, 32]가 된다. 순서대로 너비(3), 높이(3), 입력 채널(1), 출력 채널(32)을 뜻한다. 32개의 출력이 만들어진다.<br><br>\n",
    "![ㅎㅇ](https://img1.daumcdn.net/thumb/R720x0.q80/?scode=mtistory&fname=http%3A%2F%2Fcfile7.uf.tistory.com%2Fimage%2F2541F94857ABEB59147FA2)\n",
    "\n",
    "- 여담이지만 물론 Tensorflow를 이용 안하고 직접 코딩할 수도 있습니다. 그래프를 구현하고, 계산식을 넣고, Stride를 직접 반복문으로 움직이고, 학습데이터(미분값)을 저장해서 다음 그래프에 넘기고..\n",
    "- 근데 존시나 어려우니까 그냥 Tensorflow 씁시다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "image = np.array([[[[1],[2],[3]],\n",
    "                   [[4],[5],[6]], \n",
    "                   [[7],[8],[9]]]], dtype=np.float32)\n",
    "print(image.shape)\n",
    "plt.imshow(image.reshape(3,3), cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
